{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeae0240-cae0-4331-9df2-7c7433145acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48dadbca-05f8-4449-b1ad-2cbb31a68287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_root = \"./results/split_text\"\n",
    "save_root = \"./text_feature\"\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "# Load encoder (example: KoSimCSE or multilingual model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "model.eval().cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4798b62e-be07-4faa-ab50-fda56c26ddd7",
   "metadata": {},
   "source": [
    "## CLS 토큰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99fc00a6-f5dd-48c0-9323-4ef94fa52336",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tunnel: 100%|██████████████████████████████████| 51/51 [00:00<00:00, 143.40it/s]\n",
      "vinny: 100%|█████████████████████████████████████| 5/5 [00:00<00:00, 281.33it/s]\n",
      "prettymouth: 100%|█████████████████████████████| 22/22 [00:00<00:00, 303.60it/s]\n",
      "notthefallshortscram: 100%|████████████████████| 18/18 [00:00<00:00, 303.99it/s]\n",
      "21styear: 100%|██████████████████████████████| 111/111 [00:00<00:00, 313.43it/s]\n",
      "santa: 100%|█████████████████████████████████████| 5/5 [00:00<00:00, 291.04it/s]\n",
      "milkywaysynonyms: 100%|████████████████████████| 13/13 [00:00<00:00, 316.16it/s]\n",
      "shapesphysical: 100%|██████████████████████████| 13/13 [00:00<00:00, 313.83it/s]\n",
      "milkywayoriginal: 100%|████████████████████████| 13/13 [00:00<00:00, 298.61it/s]\n",
      "shapessocial: 100%|████████████████████████████| 13/13 [00:00<00:00, 326.73it/s]\n",
      "milkywayvodka: 100%|███████████████████████████| 13/13 [00:00<00:00, 277.24it/s]\n",
      "black: 100%|███████████████████████████████████| 26/26 [00:00<00:00, 317.61it/s]\n",
      "friends: 100%|███████████████████████████████████| 5/5 [00:00<00:00, 306.52it/s]\n",
      "pieman: 100%|██████████████████████████████████| 14/14 [00:00<00:00, 323.14it/s]\n",
      "upintheair: 100%|████████████████████████████████| 6/6 [00:00<00:00, 316.28it/s]\n",
      "lucy: 100%|████████████████████████████████████| 18/18 [00:00<00:00, 305.15it/s]\n",
      "merlin: 100%|██████████████████████████████████| 29/29 [00:00<00:00, 293.73it/s]\n",
      "notthefallintact: 100%|████████████████████████| 18/18 [00:00<00:00, 291.02it/s]\n",
      "notthefalllongscram: 100%|█████████████████████| 18/18 [00:00<00:00, 307.86it/s]\n",
      "slumlordreach: 100%|███████████████████████████| 57/57 [00:00<00:00, 305.41it/s]\n",
      "bronx: 100%|███████████████████████████████████| 17/17 [00:00<00:00, 303.08it/s]\n",
      "seinfeld: 100%|██████████████████████████████████| 5/5 [00:00<00:00, 290.55it/s]\n",
      "forgot: 100%|██████████████████████████████████| 27/27 [00:00<00:00, 308.58it/s]\n",
      "bigbang: 100%|███████████████████████████████████| 5/5 [00:00<00:00, 280.97it/s]\n",
      "shame: 100%|█████████████████████████████████████| 5/5 [00:00<00:00, 302.96it/s]\n",
      "himym: 100%|█████████████████████████████████████| 5/5 [00:00<00:00, 287.62it/s]\n",
      "sherlock: 100%|████████████████████████████████| 35/35 [00:00<00:00, 290.36it/s]\n",
      "piemanpni: 100%|███████████████████████████████| 13/13 [00:00<00:00, 316.39it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_text_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "    return embeddings.squeeze(0).cpu()\n",
    "\n",
    "for story_name in os.listdir(text_root):\n",
    "    story_path = os.path.join(text_root, story_name)\n",
    "    if not os.path.isdir(story_path): continue\n",
    "\n",
    "    save_story_dir = os.path.join(save_root, story_name)\n",
    "    os.makedirs(save_story_dir, exist_ok=True)\n",
    "\n",
    "    text_files = sorted([f for f in os.listdir(story_path) if f.endswith(\".txt\")])\n",
    "    for f in tqdm(text_files, desc=story_name):\n",
    "        with open(os.path.join(story_path, f), \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read().strip()\n",
    "        emb = get_text_embedding(text)\n",
    "        torch.save(emb, os.path.join(save_story_dir, f.replace(\".txt\", \".pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1701b4-f5b6-49c1-b37e-a6fe8a530df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_root = \"./results/split_text\"\n",
    "save_root = \"./text_feature_pooling\"\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "# Load encoder (example: KoSimCSE or multilingual model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "model.eval().cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dd93c6-967e-4bfe-a650-1f110600d005",
   "metadata": {},
   "source": [
    "## mean Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbf3b0c2-55b2-45fb-8006-696c120482ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tunnel: 100%|██████████████████████████████████| 51/51 [00:00<00:00, 289.95it/s]\n",
      "vinny: 100%|█████████████████████████████████████| 5/5 [00:00<00:00, 285.56it/s]\n",
      "prettymouth: 100%|█████████████████████████████| 22/22 [00:00<00:00, 299.07it/s]\n",
      "notthefallshortscram: 100%|████████████████████| 18/18 [00:00<00:00, 309.21it/s]\n",
      "21styear: 100%|██████████████████████████████| 111/111 [00:00<00:00, 310.99it/s]\n",
      "santa: 100%|█████████████████████████████████████| 5/5 [00:00<00:00, 296.94it/s]\n",
      "milkywaysynonyms: 100%|████████████████████████| 13/13 [00:00<00:00, 318.49it/s]\n",
      "shapesphysical: 100%|██████████████████████████| 13/13 [00:00<00:00, 317.72it/s]\n",
      "milkywayoriginal: 100%|████████████████████████| 13/13 [00:00<00:00, 306.56it/s]\n",
      "shapessocial: 100%|████████████████████████████| 13/13 [00:00<00:00, 324.32it/s]\n",
      "milkywayvodka: 100%|███████████████████████████| 13/13 [00:00<00:00, 289.33it/s]\n",
      "black: 100%|███████████████████████████████████| 26/26 [00:00<00:00, 317.00it/s]\n",
      "friends: 100%|███████████████████████████████████| 5/5 [00:00<00:00, 312.57it/s]\n",
      "pieman: 100%|██████████████████████████████████| 14/14 [00:00<00:00, 325.14it/s]\n",
      "upintheair: 100%|████████████████████████████████| 6/6 [00:00<00:00, 309.03it/s]\n",
      "lucy: 100%|████████████████████████████████████| 18/18 [00:00<00:00, 309.40it/s]\n",
      "merlin: 100%|██████████████████████████████████| 29/29 [00:00<00:00, 279.33it/s]\n",
      "notthefallintact: 100%|████████████████████████| 18/18 [00:00<00:00, 276.07it/s]\n",
      "notthefalllongscram: 100%|█████████████████████| 18/18 [00:00<00:00, 301.53it/s]\n",
      "slumlordreach: 100%|███████████████████████████| 57/57 [00:00<00:00, 306.37it/s]\n",
      "bronx: 100%|███████████████████████████████████| 17/17 [00:00<00:00, 305.55it/s]\n",
      "seinfeld: 100%|██████████████████████████████████| 5/5 [00:00<00:00, 299.30it/s]\n",
      "forgot: 100%|██████████████████████████████████| 27/27 [00:00<00:00, 313.36it/s]\n",
      "bigbang: 100%|███████████████████████████████████| 5/5 [00:00<00:00, 263.49it/s]\n",
      "shame: 100%|█████████████████████████████████████| 5/5 [00:00<00:00, 302.82it/s]\n",
      "himym: 100%|█████████████████████████████████████| 5/5 [00:00<00:00, 308.31it/s]\n",
      "sherlock: 100%|████████████████████████████████| 35/35 [00:00<00:00, 285.76it/s]\n",
      "piemanpni: 100%|███████████████████████████████| 13/13 [00:00<00:00, 267.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Mean pooling embedding\n",
    "def get_text_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        token_embeddings = outputs.last_hidden_state  # (1, seq_len, hidden_size)\n",
    "        attention_mask = inputs[\"attention_mask\"]      # (1, seq_len)\n",
    "\n",
    "        # Expand mask to match embedding size\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "\n",
    "        # Sum and average\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, dim=1)\n",
    "        sum_mask = input_mask_expanded.sum(dim=1)\n",
    "        mean_embeddings = sum_embeddings / sum_mask\n",
    "\n",
    "    return mean_embeddings.squeeze(0).cpu()\n",
    "\n",
    "# Feature 저장\n",
    "for story_name in os.listdir(text_root):\n",
    "    story_path = os.path.join(text_root, story_name)\n",
    "    if not os.path.isdir(story_path):\n",
    "        continue\n",
    "\n",
    "    save_story_dir = os.path.join(save_root, story_name)\n",
    "    os.makedirs(save_story_dir, exist_ok=True)\n",
    "\n",
    "    text_files = sorted([f for f in os.listdir(story_path) if f.endswith(\".txt\")])\n",
    "    for f in tqdm(text_files, desc=story_name):\n",
    "        with open(os.path.join(story_path, f), \"r\", encoding=\"utf-8\") as file:\n",
    "            text = file.read().strip()\n",
    "        emb = get_text_embedding(text)\n",
    "        torch.save(emb, os.path.join(save_story_dir, f.replace(\".txt\", \".pt\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348d513-736d-4b9a-bc4d-45cf97a41c58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
