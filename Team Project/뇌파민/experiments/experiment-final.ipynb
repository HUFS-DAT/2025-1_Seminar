{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6846304f-9254-4266-bc49-b458e53fda5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /home/dhai/coding/brain_project\n",
      "✅ train: 505, val: 159, test: 195\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import glob\n",
    "sys.path.append(\"../\")\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.optim import AdamW\n",
    "from utils.custom_scheduler import CustomCosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import GradScaler\n",
    "from tqdm import trange\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "os.chdir(\"/home/dhai/coding/brain_project\")\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())\n",
    "\n",
    "# 상위 폴더로 이동한 경로로 파일 불러오기\n",
    "df = pd.read_csv(\"./dataloader.csv\")\n",
    "\n",
    "# split 기준으로 나누기\n",
    "train_df = df[df[\"split\"] == \"train\"].reset_index(drop=True)\n",
    "val_df   = df[df[\"split\"] == \"val\"].reset_index(drop=True)\n",
    "test_df  = df[df[\"split\"] == \"test\"].reset_index(drop=True)\n",
    "\n",
    "# 확인\n",
    "print(f\"✅ train: {len(train_df)}, val: {len(val_df)}, test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd9d633a-9146-45b4-ab66-4148621d6175",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FMRIDataset(Dataset):\n",
    "    def __init__(self, df, label_map):\n",
    "        self.stories = []\n",
    "        self.label_map = label_map\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            fmri_path = row[\"run_path\"]\n",
    "            label = self.label_map[row[\"ground_truth\"]]\n",
    "            age = float(row[\"age\"])  # adition infomation age\n",
    "\n",
    "            text_dirs = [p.strip() for p in row[\"text_path\"].split(\",\")]\n",
    "            text_counts = [int(n) for n in str(row[\"text_frame\"]).split(\",\")]\n",
    "            fmri_files = sorted(\n",
    "                glob.glob(os.path.join(fmri_path, \"frame_*.pt\")),\n",
    "                key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split(\"_\")[1])\n",
    "            )\n",
    "            assert len(fmri_files) == sum(text_counts), f\"{fmri_path}: 파일 수 불일치\"\n",
    "            text_files_all = []\n",
    "            for dir_path, count in zip(text_dirs, text_counts):\n",
    "                # text_block_1.pt ~ text_block_count.pt\n",
    "                text_files = sorted(\n",
    "                    glob.glob(os.path.join(dir_path, \"text_block_*.pt\")),\n",
    "                    key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split(\"_\")[2])\n",
    "                )\n",
    "                # 만약 text_block_1.pt부터 시작이라면 text_files[:count]로 매칭\n",
    "                text_files_all.extend(text_files[:count])\n",
    "\n",
    "            # fmri와 text feature를 1:1로 매칭\n",
    "            assert len(fmri_files) == len(text_files_all), f\"{fmri_path}: 파일 수 불일치 fmri:{len(fmri_files)} text:{len(text_files_all)}\"\n",
    "            self.stories.append({\n",
    "                \"fmri_feats\": fmri_files,\n",
    "                \"text_feats\": text_files_all,\n",
    "                \"label\": label,\n",
    "                \"age\": age\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.stories)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        story = self.stories[idx]\n",
    "        fmri_feats = torch.stack([torch.load(f).float() for f in story[\"fmri_feats\"]])  # [num_frames, fmri_dim]\n",
    "        text_feats = torch.stack([torch.load(f).float() for f in story[\"text_feats\"]])  # [num_frames, text_dim]\n",
    "        age_tensor = torch.tensor([story[\"age\"]]).float()\n",
    "        age_feats = age_tensor.expand(text_feats.size(0), 1)  # [num_frames, 1]\n",
    "        text_feats = torch.cat([text_feats, age_feats], dim=1)  # [num_frames, text_dim+1]\n",
    "        label = story[\"label\"]\n",
    "        return fmri_feats, text_feats, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f479c235-48e6-4d76-9f56-59a73f21005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttnPooling(nn.Module):\n",
    "    def __init__(self, fmri_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(fmri_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, num_frames, fmri_dim]\n",
    "        attn_weights = self.attn(x).softmax(dim=1)  # [batch, num_frames, 1]\n",
    "        pooled = (x * attn_weights).sum(dim=1)      # [batch, fmri_dim]\n",
    "        return pooled\n",
    "        \n",
    "class TextToFMRI_Classifier(nn.Module):\n",
    "    def __init__(self, text_dim, fmri_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.reg_head = nn.Sequential(\n",
    "            nn.Linear(text_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, fmri_dim)\n",
    "        )\n",
    "        self.attn_pool = SelfAttnPooling(fmri_dim, hidden_dim)\n",
    "        self.class_head = nn.Sequential(\n",
    "            nn.Linear(fmri_dim, hidden_dim),  # <-- 입력 차원 바뀜\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, text_feats):\n",
    "        # text_feats: [batch, num_frames, text_dim]\n",
    "        pred_fmri = self.reg_head(text_feats)              # [batch, num_frames, fmri_dim]\n",
    "        pooled_fmri = pred_fmri.mean(dim=1)            # [batch, fmri_dim]\n",
    "        pooled_text = text_feats.mean(dim=1)               # [batch, text_dim] (or other pooling)\n",
    "        #concat = torch.cat([pooled_fmri, pooled_text], dim=-1)  # [batch, fmri_dim + text_dim]\n",
    "        class_out = self.class_head(pooled_fmri)\n",
    "        return pred_fmri, class_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9da2fe58-aec6-4d0d-871c-c0d070594c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, optimizer, scaler=None, writer=None, epoch=0, alpha=5.0):\n",
    "    model.train()\n",
    "    total_loss, total_reg_loss, total_cos_loss, total_cls_loss = 0, 0, 0, 0\n",
    "    loss_reg = nn.MSELoss()\n",
    "    #cosine_loss = nn.CosineEmbeddingLoss()\n",
    "    loss_cls = nn.CrossEntropyLoss()\n",
    "    for i, (fmri, text, label) in enumerate(dataloader):\n",
    "        fmri, text, label = fmri.cuda(), text.cuda(), label.cuda()\n",
    "        #fmri = fmri.squeeze(0)   # [num_frames, fmri_dim]\n",
    "        #text = text.squeeze(0)   # [num_frames, text_dim]\n",
    "        #label = label.squeeze(0) # scalar\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if scaler:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred_fmri, pred_label = model(text)  # [1, num_frames, fmri_dim]\n",
    "                pooled_fmri = pred_fmri.mean(dim=1)\n",
    "                pooled_text = text.mean(dim=1)\n",
    "\n",
    "                class_out = model.class_head(pooled_fmri)\n",
    "\n",
    "                reg_loss = loss_reg(pred_fmri, fmri)\n",
    "                cls_loss = loss_cls(class_out, label)\n",
    "                loss = reg_loss + alpha * cls_loss\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            pred_fmri, pred_label = model(text)\n",
    "            reg_loss = loss_reg(pred_fmri, fmri)\n",
    "            #cos_target = torch.ones(fmri.shape[0]*fmri.shape[1]).cuda()\n",
    "            #cos_loss = cosine_loss(pred_fmri.reshape(-1, fmri.shape[-1]), fmri.reshape(-1, fmri.shape[-1]), cos_target)\n",
    "            cls_loss = loss_cls(pred_label, label)\n",
    "            loss = reg_loss + cls_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_reg_loss += reg_loss.item()\n",
    "        #total_cos_loss += cos_loss.item()\n",
    "        total_cls_loss += cls_loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_reg_loss = total_reg_loss / len(dataloader)\n",
    "    #avg_cos_loss = total_cos_loss / len(dataloader)\n",
    "    avg_cls_loss = total_cls_loss / len(dataloader)\n",
    "\n",
    "    if writer:\n",
    "        writer.add_scalar('LearningRate/Train_lr', optimizer.param_groups[0]['lr'], epoch)     \n",
    "        writer.add_scalar('Train/TotalLoss', avg_loss, epoch)\n",
    "        writer.add_scalar('Train/RegLoss', avg_reg_loss, epoch)\n",
    "        #writer.add_scalar('Train/CosLoss', avg_cos_loss, epoch)\n",
    "        writer.add_scalar('Train/ClsLoss', avg_cls_loss, epoch)\n",
    "    return avg_loss\n",
    "\n",
    "def validate_epoch_pretrain(dataloader, model, epoch, writer=None):\n",
    "    model.eval()\n",
    "    total_loss, total_reg_loss, total_cos_loss, total_cls_loss = 0, 0, 0, 0\n",
    "    loss_reg = nn.MSELoss()\n",
    "    #cosine_loss = nn.CosineEmbeddingLoss()\n",
    "    loss_cls = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for fmri, text, label in dataloader:\n",
    "            fmri, text, label = fmri.cuda(), text.cuda(), label.cuda()\n",
    "            #fmri = fmri.squeeze(0)\n",
    "            #text = text.squeeze(0)\n",
    "            #label = label.squeeze(0)\n",
    "\n",
    "            pred_fmri, pred_label = model(text)\n",
    "            reg_loss = loss_reg(pred_fmri, fmri)\n",
    "            #cos_target = torch.ones(fmri.shape[0]*fmri.shape[1]).cuda()\n",
    "            #cos_loss = cosine_loss(pred_fmri.reshape(-1, fmri.shape[-1]), fmri.reshape(-1, fmri.shape[-1]), cos_target)\n",
    "            cls_loss = loss_cls(pred_label, label)\n",
    "            loss = reg_loss + cls_loss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_reg_loss += reg_loss.item()\n",
    "            #total_cos_loss += cos_loss.item()\n",
    "            total_cls_loss += cls_loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_reg_loss = total_reg_loss / len(dataloader)\n",
    "    #avg_cos_loss = total_cos_loss / len(dataloader)\n",
    "    avg_cls_loss = total_cls_loss / len(dataloader)\n",
    "    if writer:\n",
    "        writer.add_scalar('Val/TotalLoss', avg_loss, epoch)\n",
    "        writer.add_scalar('Val/RegLoss', avg_reg_loss, epoch)\n",
    "        #writer.add_scalar('Val/CosLoss', avg_cos_loss, epoch)\n",
    "        writer.add_scalar('Val/ClsLoss', avg_cls_loss, epoch)\n",
    "    return avg_loss, avg_reg_loss, avg_cls_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "500541bb-5659-4b04-9d93-5904c48776ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\"all\": 0, \"15\": 1, \"19\": 2}\n",
    "batch_sizes = 1\n",
    "train_dataset = FMRIDataset(train_df, label_map)\n",
    "val_dataset   = FMRIDataset(val_df, label_map)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_sizes, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cff49fe0-d152-4e23-816f-30b05b5234e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18137/1247874104.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=0, effective_epoch=0, T_cur=0, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=0, T_cur=0, current_cycle=0, _last_lr=[2e-05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18137/1524043791.py:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "  2%|▉                                           | 1/50 [00:03<03:04,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=0, effective_epoch=0, T_cur=0, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=0, T_cur=0, current_cycle=0, _last_lr=[2e-05]\n",
      "[1/50] TrainLoss: 5.6791  ValLoss: 1.9138 val_regloss: 0.4929 val_clsloss: 1.4209\n",
      "save best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▊                                          | 2/50 [00:07<02:59,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=1, effective_epoch=1, T_cur=1, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=1, T_cur=1, current_cycle=0, _last_lr=[1.9980267284282718e-05]\n",
      "[2/50] TrainLoss: 4.3203  ValLoss: 1.6591 val_regloss: 0.4080 val_clsloss: 1.2510\n",
      "save best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▋                                         | 3/50 [00:11<02:55,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=2, effective_epoch=2, T_cur=2, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=2, T_cur=2, current_cycle=0, _last_lr=[1.9921147013144782e-05]\n",
      "[3/50] TrainLoss: 2.1685  ValLoss: 1.6448 val_regloss: 0.3500 val_clsloss: 1.2949\n",
      "save best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▌                                        | 4/50 [00:14<02:51,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=3, effective_epoch=3, T_cur=3, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=3, T_cur=3, current_cycle=0, _last_lr=[1.982287250728689e-05]\n",
      "[4/50] TrainLoss: 0.9686  ValLoss: 1.9993 val_regloss: 0.3110 val_clsloss: 1.6883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████▍                                       | 5/50 [00:18<02:47,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=4, effective_epoch=4, T_cur=4, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=4, T_cur=4, current_cycle=0, _last_lr=[1.9685831611286312e-05]\n",
      "[5/50] TrainLoss: 0.5291  ValLoss: 1.9002 val_regloss: 0.2769 val_clsloss: 1.6233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█████▎                                      | 6/50 [00:22<02:44,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=5, effective_epoch=5, T_cur=5, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=5, T_cur=5, current_cycle=0, _last_lr=[1.9510565162951538e-05]\n",
      "[6/50] TrainLoss: 0.3656  ValLoss: 1.9182 val_regloss: 0.2517 val_clsloss: 1.6666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|██████▏                                     | 7/50 [00:26<02:40,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=6, effective_epoch=6, T_cur=6, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=6, T_cur=6, current_cycle=0, _last_lr=[1.9297764858882516e-05]\n",
      "[7/50] TrainLoss: 0.2888  ValLoss: 1.9276 val_regloss: 0.2364 val_clsloss: 1.6912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|███████                                     | 8/50 [00:29<02:35,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=7, effective_epoch=7, T_cur=7, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=7, T_cur=7, current_cycle=0, _last_lr=[1.9048270524660197e-05]\n",
      "[8/50] TrainLoss: 0.2444  ValLoss: 1.7978 val_regloss: 0.2253 val_clsloss: 1.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████▉                                    | 9/50 [00:33<02:31,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=8, effective_epoch=8, T_cur=8, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=8, T_cur=8, current_cycle=0, _last_lr=[1.8763066800438638e-05]\n",
      "[9/50] TrainLoss: 0.2172  ValLoss: 1.8793 val_regloss: 0.2223 val_clsloss: 1.6570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 10/50 [00:37<02:27,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=9, effective_epoch=9, T_cur=9, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=9, T_cur=9, current_cycle=0, _last_lr=[1.8443279255020153e-05]\n",
      "[10/50] TrainLoss: 0.1993  ValLoss: 1.7820 val_regloss: 0.2215 val_clsloss: 1.5605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|█████████▍                                 | 11/50 [00:40<02:23,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=10, effective_epoch=10, T_cur=10, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=10, T_cur=10, current_cycle=0, _last_lr=[1.8090169943749477e-05]\n",
      "[11/50] TrainLoss: 0.1865  ValLoss: 1.7804 val_regloss: 0.2174 val_clsloss: 1.5630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██████████▎                                | 12/50 [00:44<02:19,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=11, effective_epoch=11, T_cur=11, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=11, T_cur=11, current_cycle=0, _last_lr=[1.7705132427757895e-05]\n",
      "[12/50] TrainLoss: 0.1761  ValLoss: 1.7705 val_regloss: 0.2184 val_clsloss: 1.5521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|███████████▏                               | 13/50 [00:48<02:15,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=12, effective_epoch=12, T_cur=12, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=12, T_cur=12, current_cycle=0, _last_lr=[1.7289686274214116e-05]\n",
      "[13/50] TrainLoss: 0.1674  ValLoss: 1.7012 val_regloss: 0.2182 val_clsloss: 1.4830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|████████████                               | 14/50 [00:51<02:11,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=13, effective_epoch=13, T_cur=13, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=13, T_cur=13, current_cycle=0, _last_lr=[1.684547105928689e-05]\n",
      "[14/50] TrainLoss: 0.1594  ValLoss: 1.6885 val_regloss: 0.2146 val_clsloss: 1.4738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████▉                              | 15/50 [00:55<02:08,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=14, effective_epoch=14, T_cur=14, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=14, T_cur=14, current_cycle=0, _last_lr=[1.63742398974869e-05]\n",
      "[15/50] TrainLoss: 0.1522  ValLoss: 1.6911 val_regloss: 0.2163 val_clsloss: 1.4748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|█████████████▊                             | 16/50 [00:59<02:04,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=15, effective_epoch=15, T_cur=15, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=15, T_cur=15, current_cycle=0, _last_lr=[1.5877852522924736e-05]\n",
      "[16/50] TrainLoss: 0.1452  ValLoss: 1.6673 val_regloss: 0.2170 val_clsloss: 1.4503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|██████████████▌                            | 17/50 [01:02<02:01,  3.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=16, effective_epoch=16, T_cur=16, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=16, T_cur=16, current_cycle=0, _last_lr=[1.5358267949789968e-05]\n",
      "[17/50] TrainLoss: 0.1388  ValLoss: 1.6947 val_regloss: 0.2105 val_clsloss: 1.4843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███████████████▍                           | 18/50 [01:06<01:57,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=17, effective_epoch=17, T_cur=17, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=17, T_cur=17, current_cycle=0, _last_lr=[1.4817536741017153e-05]\n",
      "[18/50] TrainLoss: 0.1324  ValLoss: 1.6908 val_regloss: 0.2150 val_clsloss: 1.4758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████▎                          | 19/50 [01:10<01:54,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=18, effective_epoch=18, T_cur=18, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=18, T_cur=18, current_cycle=0, _last_lr=[1.4257792915650728e-05]\n",
      "[19/50] TrainLoss: 0.1266  ValLoss: 1.6740 val_regloss: 0.2074 val_clsloss: 1.4665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████▏                         | 20/50 [01:13<01:51,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=19, effective_epoch=19, T_cur=19, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=19, T_cur=19, current_cycle=0, _last_lr=[1.3681245526846782e-05]\n",
      "[20/50] TrainLoss: 0.1205  ValLoss: 1.6738 val_regloss: 0.2044 val_clsloss: 1.4695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████████                         | 21/50 [01:17<01:46,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=20, effective_epoch=20, T_cur=20, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=20, T_cur=20, current_cycle=0, _last_lr=[1.3090169943749475e-05]\n",
      "[21/50] TrainLoss: 0.1148  ValLoss: 1.6704 val_regloss: 0.1974 val_clsloss: 1.4730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|██████████████████▉                        | 22/50 [01:21<01:44,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=21, effective_epoch=21, T_cur=21, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=21, T_cur=21, current_cycle=0, _last_lr=[1.2486898871648547e-05]\n",
      "[22/50] TrainLoss: 0.1096  ValLoss: 1.6220 val_regloss: 0.1970 val_clsloss: 1.4250\n",
      "save best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|███████████████████▊                       | 23/50 [01:25<01:40,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=22, effective_epoch=22, T_cur=22, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=22, T_cur=22, current_cycle=0, _last_lr=[1.187381314585725e-05]\n",
      "[23/50] TrainLoss: 0.1050  ValLoss: 1.6437 val_regloss: 0.1975 val_clsloss: 1.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████▋                      | 24/50 [01:28<01:36,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=23, effective_epoch=23, T_cur=23, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=23, T_cur=23, current_cycle=0, _last_lr=[1.1253332335643045e-05]\n",
      "[24/50] TrainLoss: 0.1009  ValLoss: 1.5827 val_regloss: 0.1921 val_clsloss: 1.3906\n",
      "save best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████▌                     | 25/50 [01:32<01:32,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=24, effective_epoch=24, T_cur=24, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=24, T_cur=24, current_cycle=0, _last_lr=[1.0627905195293135e-05]\n",
      "[25/50] TrainLoss: 0.0974  ValLoss: 1.6320 val_regloss: 0.1873 val_clsloss: 1.4447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████▎                    | 26/50 [01:36<01:28,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=25, effective_epoch=25, T_cur=25, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=25, T_cur=25, current_cycle=0, _last_lr=[1e-05]\n",
      "[26/50] TrainLoss: 0.0944  ValLoss: 1.5854 val_regloss: 0.1917 val_clsloss: 1.3937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████▏                   | 27/50 [01:39<01:24,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=26, effective_epoch=26, T_cur=26, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=26, T_cur=26, current_cycle=0, _last_lr=[9.372094804706867e-06]\n",
      "[27/50] TrainLoss: 0.0919  ValLoss: 1.6083 val_regloss: 0.1889 val_clsloss: 1.4195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|████████████████████████                   | 28/50 [01:43<01:20,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=27, effective_epoch=27, T_cur=27, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=27, T_cur=27, current_cycle=0, _last_lr=[8.74666766435696e-06]\n",
      "[28/50] TrainLoss: 0.0898  ValLoss: 1.6168 val_regloss: 0.1869 val_clsloss: 1.4298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████▉                  | 29/50 [01:47<01:17,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=28, effective_epoch=28, T_cur=28, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=28, T_cur=28, current_cycle=0, _last_lr=[8.126186854142754e-06]\n",
      "[29/50] TrainLoss: 0.0879  ValLoss: 1.6122 val_regloss: 0.1849 val_clsloss: 1.4273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████▊                 | 30/50 [01:50<01:13,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=29, effective_epoch=29, T_cur=29, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=29, T_cur=29, current_cycle=0, _last_lr=[7.513101128351452e-06]\n",
      "[30/50] TrainLoss: 0.0864  ValLoss: 1.5590 val_regloss: 0.1853 val_clsloss: 1.3737\n",
      "save best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████████████████████████▋                | 31/50 [01:54<01:10,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=30, effective_epoch=30, T_cur=30, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=30, T_cur=30, current_cycle=0, _last_lr=[6.9098300562505296e-06]\n",
      "[31/50] TrainLoss: 0.0851  ValLoss: 1.5572 val_regloss: 0.1831 val_clsloss: 1.3741\n",
      "save best model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|███████████████████████████▌               | 32/50 [01:58<01:07,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=31, effective_epoch=31, T_cur=31, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=31, T_cur=31, current_cycle=0, _last_lr=[6.318754473153224e-06]\n",
      "[32/50] TrainLoss: 0.0838  ValLoss: 1.5897 val_regloss: 0.1819 val_clsloss: 1.4078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|████████████████████████████▍              | 33/50 [02:02<01:03,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=32, effective_epoch=32, T_cur=32, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=32, T_cur=32, current_cycle=0, _last_lr=[5.742207084349274e-06]\n",
      "[33/50] TrainLoss: 0.0829  ValLoss: 1.5668 val_regloss: 0.1817 val_clsloss: 1.3851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|█████████████████████████████▏             | 34/50 [02:05<00:59,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=33, effective_epoch=33, T_cur=33, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=33, T_cur=33, current_cycle=0, _last_lr=[5.1824632589828465e-06]\n",
      "[34/50] TrainLoss: 0.0820  ValLoss: 1.6431 val_regloss: 0.1815 val_clsloss: 1.4616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████             | 35/50 [02:09<00:56,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=34, effective_epoch=34, T_cur=34, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=34, T_cur=34, current_cycle=0, _last_lr=[4.641732050210032e-06]\n",
      "[35/50] TrainLoss: 0.0812  ValLoss: 1.6045 val_regloss: 0.1806 val_clsloss: 1.4239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|██████████████████████████████▉            | 36/50 [02:13<00:52,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=35, effective_epoch=35, T_cur=35, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=35, T_cur=35, current_cycle=0, _last_lr=[4.12214747707527e-06]\n",
      "[36/50] TrainLoss: 0.0806  ValLoss: 1.6435 val_regloss: 0.1799 val_clsloss: 1.4636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████▊           | 37/50 [02:17<00:49,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=36, effective_epoch=36, T_cur=36, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=36, T_cur=36, current_cycle=0, _last_lr=[3.625760102513103e-06]\n",
      "[37/50] TrainLoss: 0.0800  ValLoss: 1.5639 val_regloss: 0.1813 val_clsloss: 1.3826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|████████████████████████████████▋          | 38/50 [02:21<00:47,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=37, effective_epoch=37, T_cur=37, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=37, T_cur=37, current_cycle=0, _last_lr=[3.1545289407131128e-06]\n",
      "[38/50] TrainLoss: 0.0795  ValLoss: 1.6141 val_regloss: 0.1821 val_clsloss: 1.4320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|█████████████████████████████████▌         | 39/50 [02:25<00:42,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=38, effective_epoch=38, T_cur=38, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=38, T_cur=38, current_cycle=0, _last_lr=[2.7103137257858867e-06]\n",
      "[39/50] TrainLoss: 0.0791  ValLoss: 1.6111 val_regloss: 0.1813 val_clsloss: 1.4299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████▍        | 40/50 [02:28<00:38,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=39, effective_epoch=39, T_cur=39, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=39, T_cur=39, current_cycle=0, _last_lr=[2.2948675722421086e-06]\n",
      "[40/50] TrainLoss: 0.0787  ValLoss: 1.6004 val_regloss: 0.1801 val_clsloss: 1.4203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████████████▎       | 41/50 [02:32<00:33,  3.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=40, effective_epoch=40, T_cur=40, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=40, T_cur=40, current_cycle=0, _last_lr=[1.9098300562505266e-06]\n",
      "[41/50] TrainLoss: 0.0784  ValLoss: 1.6329 val_regloss: 0.1800 val_clsloss: 1.4529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████████████████████████████████       | 42/50 [02:36<00:29,  3.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=41, effective_epoch=41, T_cur=41, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=41, T_cur=41, current_cycle=0, _last_lr=[1.5567207449798517e-06]\n",
      "[42/50] TrainLoss: 0.0782  ValLoss: 1.6342 val_regloss: 0.1802 val_clsloss: 1.4540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████████████████████████████████▉      | 43/50 [02:39<00:25,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=42, effective_epoch=42, T_cur=42, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=42, T_cur=42, current_cycle=0, _last_lr=[1.2369331995613643e-06]\n",
      "[43/50] TrainLoss: 0.0780  ValLoss: 1.6297 val_regloss: 0.1801 val_clsloss: 1.4496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|█████████████████████████████████████▊     | 44/50 [02:43<00:22,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=43, effective_epoch=43, T_cur=43, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=43, T_cur=43, current_cycle=0, _last_lr=[9.517294753398066e-07]\n",
      "[44/50] TrainLoss: 0.0778  ValLoss: 1.6243 val_regloss: 0.1801 val_clsloss: 1.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████▋    | 45/50 [02:47<00:18,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=44, effective_epoch=44, T_cur=44, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=44, T_cur=44, current_cycle=0, _last_lr=[7.022351411174866e-07]\n",
      "[45/50] TrainLoss: 0.0777  ValLoss: 1.6235 val_regloss: 0.1802 val_clsloss: 1.4433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████████████▌   | 46/50 [02:50<00:14,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=45, effective_epoch=45, T_cur=45, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=45, T_cur=45, current_cycle=0, _last_lr=[4.894348370484648e-07]\n",
      "[46/50] TrainLoss: 0.0776  ValLoss: 1.6263 val_regloss: 0.1802 val_clsloss: 1.4461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|████████████████████████████████████████▍  | 47/50 [02:54<00:11,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=46, effective_epoch=46, T_cur=46, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=46, T_cur=46, current_cycle=0, _last_lr=[3.1416838871369036e-07]\n",
      "[47/50] TrainLoss: 0.0775  ValLoss: 1.6343 val_regloss: 0.1801 val_clsloss: 1.4542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████████████████████████████████████▎ | 48/50 [02:58<00:07,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=47, effective_epoch=47, T_cur=47, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=47, T_cur=47, current_cycle=0, _last_lr=[1.771274927131128e-07]\n",
      "[48/50] TrainLoss: 0.0774  ValLoss: 1.6306 val_regloss: 0.1801 val_clsloss: 1.4504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|██████████████████████████████████████████▏| 49/50 [03:01<00:03,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=48, effective_epoch=48, T_cur=48, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=48, T_cur=48, current_cycle=0, _last_lr=[7.885298685522235e-08]\n",
      "[49/50] TrainLoss: 0.0774  ValLoss: 1.6305 val_regloss: 0.1801 val_clsloss: 1.4503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [03:05<00:00,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG step] epoch=49, effective_epoch=49, T_cur=49, T_total=50, current_cycle=0, eta_max=2e-05\n",
      "[DEBUG step] After step: last_epoch=49, T_cur=49, current_cycle=0, _last_lr=[1.973271571728441e-08]\n",
      "[50/50] TrainLoss: 0.0774  ValLoss: 1.6302 val_regloss: 0.1801 val_clsloss: 1.4501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = TextToFMRI_Classifier(text_dim=769, fmri_dim=288, hidden_dim=512, num_classes=3).cuda()\n",
    "optimizer = AdamW(model.parameters(), lr=0.00002, weight_decay=0.05, betas=(0.9, 0.999))\n",
    "scheduler = CustomCosineAnnealingWarmRestarts(optimizer=optimizer, T_0=50, T_mult=2, eta_min=0, eta_max=0.00002, decay_factor=0.9, start_epoch=0)\n",
    "epochs = 50\n",
    "scaler = GradScaler()\n",
    "writer = SummaryWriter(log_dir=\"./tensorboard/experiment_9\")\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    train_loss = train_epoch(train_loader, model, optimizer, scaler, writer, epoch)\n",
    "    val_loss, reg_loss, cls_loss = validate_epoch_pretrain(val_loader, model, epoch, writer)\n",
    "    scheduler.step(epoch)\n",
    "    print(f\"[{epoch+1}/{epochs}] TrainLoss: {train_loss:.4f}  ValLoss: {val_loss:.4f} val_regloss: {reg_loss:.4f} val_clsloss: {cls_loss:.4f}\")\n",
    "\n",
    "    # Best 모델 저장\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"./experiments/experiment_9_best_model.pth\")\n",
    "        print(\"save best model\")\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21baec16-087d-4267-af05-9eaf44edc2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\"all\": 0, \"15\": 1, \"19\": 2}\n",
    "test_dataset = FMRIDataset(test_df, label_map)\n",
    "\n",
    "test_loader   = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "# 모델 정의 (TextMultiTaskNet이랑 동일해야 함)\n",
    "model = TextToFMRI_Classifier(text_dim = 769, fmri_dim = 288, hidden_dim = 512, num_classes = 3).cuda()\n",
    "model.load_state_dict(torch.load(\"./experiments/experiment_5_best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Loss 함수\n",
    "mse_loss = nn.MSELoss()\n",
    "cosine_loss = nn.CosineEmbeddingLoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "# Test loop\n",
    "total, correct = 0, 0\n",
    "total_mse, total_cos = 0, 0\n",
    "total_ce = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for fmri, text, label in test_loader:\n",
    "        fmri, text, label = fmri.cuda(), text.cuda(), label.cuda()\n",
    "        pred_fmri, pred_label = model(text)\n",
    "        \n",
    "        # Regression(MSE)\n",
    "        mse = mse_loss(pred_fmri.squeeze(0), fmri.squeeze(0))\n",
    "        total_mse += mse.item()\n",
    "        \n",
    "        # Cosine\n",
    "        cos_target = torch.ones(fmri.squeeze(0).shape[0]).cuda()\n",
    "        cos = cosine_loss(pred_fmri.squeeze(0), fmri.squeeze(0), cos_target)\n",
    "        total_cos += cos.item()\n",
    "        \n",
    "        # Classification\n",
    "        ce = ce_loss(pred_label, label)\n",
    "        total_ce += ce.item()\n",
    "        preds = pred_label.argmax(dim=1)\n",
    "        correct += (preds == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "avg_mse = total_mse / len(test_loader)\n",
    "avg_cos = total_cos / len(test_loader)\n",
    "avg_ce = total_ce / len(test_loader)\n",
    "acc = correct / total\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test MSE Loss: {avg_mse:.4f}\")\n",
    "print(f\"Test Cosine Loss: {avg_cos:.4f}\")\n",
    "print(f\"Test CrossEntropy Loss: {avg_ce:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4636973e-1f5d-4dce-8750-dc006099718f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0000\n",
      "Test MSE Loss: 0.1030\n",
      "Test CrossEntropy Loss: 0.4524\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 46   0   0]\n",
      " [  0 103   0]\n",
      " [  0   0  46]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         all       1.00      1.00      1.00        46\n",
      "          15       1.00      1.00      1.00       103\n",
      "          19       1.00      1.00      1.00        46\n",
      "\n",
      "    accuracy                           1.00       195\n",
      "   macro avg       1.00      1.00      1.00       195\n",
      "weighted avg       1.00      1.00      1.00       195\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "label_map = {\"all\": 0, \"15\": 1, \"19\": 2}\n",
    "inv_label_map = {v: k for k, v in label_map.items()}  # 숫자를 다시 텍스트로 바꿀 때\n",
    "\n",
    "test_dataset = FMRIDataset(test_df, label_map)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=1)\n",
    "\n",
    "model = TextToFMRI_Classifier(text_dim=769, fmri_dim=288, hidden_dim=512, num_classes=3).cuda()\n",
    "model.load_state_dict(torch.load(\"./experiments/experiment_9_best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "#cosine_loss = nn.CosineEmbeddingLoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "total, correct = 0, 0\n",
    "total_mse, total_cos, total_ce = 0, 0, 0\n",
    "\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for fmri, text, label in test_loader:\n",
    "        fmri, text, label = fmri.cuda(), text.cuda(), label.cuda()\n",
    "        pred_fmri, pred_label = model(text)\n",
    "\n",
    "        # Regression(MSE)\n",
    "        mse = mse_loss(pred_fmri.squeeze(0), fmri.squeeze(0))\n",
    "        total_mse += mse.item()\n",
    "\n",
    "        # Cosine\n",
    "        #cos_target = torch.ones(fmri.squeeze(0).shape[0]).cuda()\n",
    "        #cos = cosine_loss(pred_fmri.squeeze(0), fmri.squeeze(0), cos_target)\n",
    "        #total_cos += cos.item()\n",
    "\n",
    "        # Classification\n",
    "        ce = ce_loss(pred_label, label)\n",
    "        total_ce += ce.item()\n",
    "        preds = pred_label.argmax(dim=1)\n",
    "        correct += (preds == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "        # 리스트에 저장 (confusion matrix, report용)\n",
    "        all_preds.append(preds.item())\n",
    "        all_labels.append(label.item())\n",
    "\n",
    "avg_mse = total_mse / len(test_loader)\n",
    "#avg_cos = total_cos / len(test_loader)\n",
    "avg_ce = total_ce / len(test_loader)\n",
    "acc = correct / total\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test MSE Loss: {avg_mse:.4f}\")\n",
    "#print(f\"Test Cosine Loss: {avg_cos:.4f}\")\n",
    "print(f\"Test CrossEntropy Loss: {avg_ce:.4f}\")\n",
    "\n",
    "# Confusion Matrix & Classification Report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(all_labels, all_preds))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"all\", \"15\", \"19\"]))\n",
    "\n",
    "# Confusion Matrix 생성\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "labels = [\"all\", \"15\", \"19\"]\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6079030-b8cf-4e9a-93e2-d895bea4cce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
