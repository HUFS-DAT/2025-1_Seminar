{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4737ec72-d4a1-4e09-821a-cc7104096265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor,HistGradientBoostingRegressor\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.metrics import make_scorer\n",
    "from catboost import CatBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0beef476-c97d-4af9-bd0f-0dff835d525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train.csv')\n",
    "test  = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a66029-7574-4b3c-8bd5-b74edebb91d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   회사_나이       투자효율      고객당_매출    직원당_매출  log_연매출(억원)  log_총 투자금(억원)  \\\n",
      "0     16   1.415330   83.578947  1.154349     8.469053       8.121480   \n",
      "1      2   0.068550    3.444444  0.066939     5.634790       8.311398   \n",
      "2      7   1.881159  220.745455  3.875199     9.404426       8.772455   \n",
      "3      9  15.836336         NaN  3.249230     9.263692       6.501290   \n",
      "4      5  11.819277  103.263158  4.979695     9.191259       6.721426   \n",
      "\n",
      "   log_기업가치(백억원)  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n"
     ]
    }
   ],
   "source": [
    "# 파생변수 만들기 \n",
    "\n",
    "## 숫자형 컬럼을 명시적으로 float 타입으로 변환\n",
    "numeric_cols = ['연매출(억원)', '총 투자금(억원)', '기업가치(백억원)']\n",
    "for col in numeric_cols:\n",
    "    train[col] = pd.to_numeric(train[col], errors='coerce').astype(float)\n",
    "    test[col]  = pd.to_numeric(test[col], errors='coerce').astype(float)\n",
    "\n",
    "# 회사_나이\n",
    "train['회사_나이']  = 2025 - train['설립연도']\n",
    "test ['회사_나이'] = 2025 - test ['설립연도']\n",
    "\n",
    "# 투자효율 (연매출 ÷ (총 투자금 + 1))\n",
    "train['투자효율']   = train['연매출(억원)'] / (train['총 투자금(억원)'] + 1)\n",
    "test ['투자효율']   = test ['연매출(억원)']  / (test ['총 투자금(억원)'] + 1)\n",
    "\n",
    "# 고객당 매출 (연매출 ÷ (고객수 + 1))\n",
    "train['고객당_매출'] = train['연매출(억원)'] / (train['고객수(백만명)'] + 1)\n",
    "test ['고객당_매출'] = test ['연매출(억원)']  / (test ['고객수(백만명)'] + 1)\n",
    "\n",
    "# 원당 매출 (연매출 ÷ (직원 수 + 1))\n",
    "train['직원당_매출'] = train['연매출(억원)'] / (train['직원 수'] + 1)\n",
    "test ['직원당_매출'] = test ['연매출(억원)']  / (test ['직원 수'] + 1)\n",
    "\n",
    "# 로그 변환 (왜곡 안정화)\n",
    "for col in numeric_cols:\n",
    "    train[f'log_{col}'] = np.log1p(train[col].fillna(0.0))\n",
    "    test [f'log_{col}'] = np.log1p(test [col].fillna(0.0))\n",
    "\n",
    "# 생성된 피처 확인\n",
    "engineered = [\n",
    "    '회사_나이', '투자효율', '고객당_매출', '직원당_매출',\n",
    "    'log_연매출(억원)', 'log_총 투자금(억원)', 'log_기업가치(백억원)'\n",
    "]\n",
    "print(train[engineered].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cd533e9-d277-45f5-8a56-cb508cc7d857",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n",
      "C:\\Users\\coghk\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py:635: UserWarning: Skipping features without any observed values: ['기업가치(백억원)']. At least one non-missing value is needed for imputation with strategy='median'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Imputer  Mean CV wMAE\n",
      "0  median      0.211957\n",
      "1     knn      0.212027\n"
     ]
    }
   ],
   "source": [
    "# 가중치 변경\n",
    "\n",
    "# 빈도 기반 샘플 가중치 생성\n",
    "counts = train['성공확률'].value_counts()\n",
    "train['weight'] = train['성공확률'].map(lambda y: 1/counts[y])\n",
    "train['weight'] /= train['weight'].mean()\n",
    "\n",
    "# 수치형 컬럼명 정의 & 결측 플래그 파생\n",
    "numeric_cols = train.select_dtypes(include=['int64','float64']) \\\n",
    "                    .columns.drop(['성공확률','weight'])\n",
    "for col in numeric_cols:\n",
    "    train[f'is_na_{col}'] = train[col].isna().astype(int)\n",
    "    test [f'is_na_{col}'] = test [col].isna().astype(int)\n",
    "\n",
    "# 범주형 NaN → 'Missing'\n",
    "cat_cols = train.select_dtypes(include=['object']) \\\n",
    "                .columns.drop('ID', errors='ignore')\n",
    "train[cat_cols] = train[cat_cols].fillna('Missing')\n",
    "test [cat_cols] = test [cat_cols].fillna('Missing')\n",
    "\n",
    "# 평가 함수 정의\n",
    "def weighted_mae(y_true, y_pred, w):\n",
    "    return np.sum(w * np.abs(y_true - y_pred)) / np.sum(w)\n",
    "\n",
    "# Imputer 비교 설정 (Median vs KNN)\n",
    "imputers = {\n",
    "    'median': SimpleImputer(strategy='median'),\n",
    "    'knn'   : KNNImputer(n_neighbors=5)\n",
    "}\n",
    "\n",
    "features = (\n",
    "    list(numeric_cols)\n",
    "  + [f'is_na_{c}' for c in numeric_cols]\n",
    "  + list(cat_cols)\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, imp in imputers.items():\n",
    "    # 전처리 파이프라인\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num',  imp,                           numeric_cols.tolist()),\n",
    "        ('flag', SimpleImputer(fill_value=0),  [f'is_na_{c}' for c in numeric_cols]),\n",
    "        ('cat',  OneHotEncoder(handle_unknown='ignore'), cat_cols.tolist())\n",
    "    ])\n",
    "    pipe = Pipeline([\n",
    "        ('prep', preprocessor),\n",
    "        ('rf',   RandomForestRegressor(\n",
    "                     n_estimators=100,\n",
    "                     max_depth=6,\n",
    "                     random_state=42\n",
    "                 ))\n",
    "    ])\n",
    "    \n",
    "    # 5-Fold CV\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    X = train[features]\n",
    "    y = train['성공확률']\n",
    "    w = train['weight']\n",
    "    \n",
    "    for tr_ix, va_ix in kf.split(X):\n",
    "        pipe.fit(\n",
    "            X.iloc[tr_ix], y.iloc[tr_ix],\n",
    "            rf__sample_weight=w.iloc[tr_ix]\n",
    "        )\n",
    "        preds = pipe.predict(X.iloc[va_ix])\n",
    "        cv_scores.append(weighted_mae(y.iloc[va_ix], preds, w.iloc[va_ix]))\n",
    "    \n",
    "    results.append((name, np.mean(cv_scores)))\n",
    "\n",
    "#결과 출력\n",
    "results_df = pd.DataFrame(results, columns=['Imputer','Mean CV wMAE'])\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2b98bdc-5ca6-4a09-9f4a-9a29d97e8cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      분야_TE     국가_TE   투자단계_TE\n",
      "0  0.527132  0.535475  0.539092\n",
      "1  0.561887  0.539879  0.542075\n",
      "2  0.534967  0.536494  0.543516\n",
      "3  0.554118  0.561027  0.546581\n",
      "4  0.536082  0.521348  0.554082\n",
      "      분야_TE     국가_TE   투자단계_TE\n",
      "0  0.567151  0.533333  0.538425\n",
      "1  0.533731  0.531303  0.538425\n",
      "2  0.539011  0.548276  0.536141\n",
      "3  0.529545  0.531303  0.546171\n",
      "4  0.567151  0.533333  0.546171\n"
     ]
    }
   ],
   "source": [
    "# 범주형 변수 target encoding\n",
    "\n",
    "# 타깃(Y)과 샘플 가중치\n",
    "y = train['성공확률'].copy()\n",
    "counts = y.value_counts()\n",
    "train['weight'] = y.map(lambda v: 1/counts[v])\n",
    "train['weight'] /= train['weight'].mean()\n",
    "\n",
    "# 인코딩할 컬럼 지정\n",
    "cat_cols = ['분야', '국가', '투자단계']  # High-cardinality 범주 세 개\n",
    "\n",
    "# CV-aware TargetEncoder 초기화\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "te = TargetEncoder(cols=cat_cols, smoothing=0.3)  \n",
    "\n",
    "# 빈 데이터프레임에 컬럼 생성\n",
    "for col in cat_cols:\n",
    "    train[f'{col}_TE'] = np.nan\n",
    "\n",
    "# Fold별로 fit→transform\n",
    "for tr_idx, va_idx in kf.split(train):\n",
    "    te.fit(train.iloc[tr_idx][cat_cols], y.iloc[tr_idx])\n",
    "    train.iloc[va_idx, train.columns.get_indexer([f'{col}_TE' for col in cat_cols])] = \\\n",
    "        te.transform(train.iloc[va_idx][cat_cols])\n",
    "\n",
    "# Test 셋에도 전체 데이터로 인코딩 적용\n",
    "te.fit(train[cat_cols], y)\n",
    "test_te = te.transform(test[cat_cols])\n",
    "for col in cat_cols:\n",
    "    test[f'{col}_TE'] = test_te[col]\n",
    "\n",
    "# 결과 확인\n",
    "engineered_te = [f'{col}_TE' for col in cat_cols]\n",
    "print(train[engineered_te].head())\n",
    "print(test[engineered_te].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "463c9b8f-bf7b-428d-a55b-52b5241fb4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost Mean CV Weighted MAE: 0.2129\n",
      "XGBoost Mean CV Weighted MAE: 0.2144\n"
     ]
    }
   ],
   "source": [
    "# model 풀 확장 : catboost, xgboost\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'CatBoost': CatBoostRegressor(\n",
    "        iterations=500,\n",
    "        learning_rate=0.05,\n",
    "        depth=6,\n",
    "        eval_metric='MAE',\n",
    "        random_seed=42,\n",
    "        verbose=False\n",
    "    ),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        objective='reg:squarederror',\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# 5-Fold CV 수행\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = {}\n",
    "\n",
    "for name, mdl in models.items():\n",
    "    cv_scores = []\n",
    "    for tr_idx, va_idx in kf.split(train):\n",
    "        X_tr = train.iloc[tr_idx][features]\n",
    "        y_tr = train.iloc[tr_idx]['성공확률']\n",
    "        w_tr = train.iloc[tr_idx]['weight']\n",
    "        \n",
    "        X_va = train.iloc[va_idx][features]\n",
    "        y_va = train.iloc[va_idx]['성공확률']\n",
    "        w_va = train.iloc[va_idx]['weight']\n",
    "        \n",
    "        # 파이프라인은 이미 preprocessor 변수로 정의되어있음\n",
    "        pipe = Pipeline([\n",
    "            ('prep', preprocessor),\n",
    "            (name, mdl)\n",
    "        ])\n",
    "        \n",
    "        # sample_weight 파라미터는 모델마다 이름이 다르므로\n",
    "        sw_param = {f'{name}__sample_weight': w_tr.values}\n",
    "        pipe.fit(X_tr, y_tr, **sw_param)\n",
    "        \n",
    "        preds = pipe.predict(X_va)\n",
    "        # weighted_mae 함수도 이미 정의되어있으니까\n",
    "        cv_scores.append(weighted_mae(y_va.values, preds, w_va.values))\n",
    "    \n",
    "    results[name] = np.mean(cv_scores)\n",
    "\n",
    "# 결과 출력\n",
    "for name, score in results.items():\n",
    "    print(f'{name} Mean CV Weighted MAE: {score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793a830e-cc8b-418d-846a-3114ae364ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "Best params: {'rf__max_depth': 17, 'rf__min_samples_leaf': 3, 'rf__min_samples_split': 2, 'rf__n_estimators': 104}\n",
      "Best CV wMAE: 0.20930381817374402\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 튜닝\n",
    "\n",
    "# 파이프라인\n",
    "pipe = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('rf',   RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# 파라미터 분포\n",
    "param_dist = {\n",
    "    'rf__n_estimators': randint(100, 1001),\n",
    "    'rf__max_depth': randint(3, 21),\n",
    "    'rf__min_samples_split': randint(2, 11),\n",
    "    'rf__min_samples_leaf': randint(1, 11)\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV 설정\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=lambda est, X, y: -weighted_mae(y, est.predict(X), train.loc[X.index, 'weight']),\n",
    "    cv=kf,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 실행\n",
    "X = train[features]\n",
    "y = train['성공확률']\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Best params:\", random_search.best_params_)\n",
    "print(\"Best CV wMAE:\", -random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe9a12c6-d497-4c4d-9051-e183f1563504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking CV Weighted MAE: 0.2099987875344944\n",
      "Weighted Blending CV Weighted MAE: 0.2149369588099207\n",
      "submission_2.csv 생성 완료\n"
     ]
    }
   ],
   "source": [
    "# stacking, blending 프로토타입\n",
    "X = train[features]\n",
    "y = train['성공확률']\n",
    "w = train['weight']\n",
    "\n",
    "# 1) Base 모델 풀 정의\n",
    "base_models = {\n",
    "    'rf' : RandomForestRegressor(n_estimators=100, max_depth=6, random_state=42),\n",
    "    'hgb': HistGradientBoostingRegressor(max_iter=300, random_state=42)\n",
    "}\n",
    "\n",
    "# 2) OOF(preds) 및 테스트(preds) 저장 공간\n",
    "oof_preds  = pd.DataFrame(index=train.index)\n",
    "test_preds = pd.DataFrame(index=test.index)\n",
    "\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in base_models.items():\n",
    "    oof      = np.zeros(len(train))\n",
    "    test_fold = np.zeros((len(test), n_folds))\n",
    "    \n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X)):\n",
    "        pipe = Pipeline([\n",
    "            ('prep', preprocessor),\n",
    "            (name, model)\n",
    "        ])\n",
    "        # 학습\n",
    "        pipe.fit(\n",
    "            X.iloc[tr_idx], y.iloc[tr_idx],\n",
    "            **{f'{name}__sample_weight': w.iloc[tr_idx].values}\n",
    "        )\n",
    "        # OOF 예측\n",
    "        oof[va_idx] = pipe.predict(X.iloc[va_idx])\n",
    "        # 테스트 폴드 예측\n",
    "        test_fold[:, fold] = pipe.predict(test[features])\n",
    "    \n",
    "    oof_preds[name]  = oof\n",
    "    test_preds[name] = test_fold.mean(axis=1)\n",
    "\n",
    "# 3) 메타 모델 학습 (Linear Regression)\n",
    "meta = LinearRegression()\n",
    "meta.fit(oof_preds, y, sample_weight=w.values)\n",
    "\n",
    "# 4) Stacking CV 성능\n",
    "stack_oof   = meta.predict(oof_preds)\n",
    "stack_wmae  = weighted_mae(y.values, stack_oof, w.values)\n",
    "print(\"Stacking CV Weighted MAE:\", stack_wmae)\n",
    "\n",
    "# 5) Weighted Blending CV 성능 (Meta 계수 기반)\n",
    "coef = np.clip(meta.coef_, 0, None)\n",
    "blend_weights = coef / coef.sum()\n",
    "\n",
    "blend_oof  = oof_preds.dot(blend_weights)\n",
    "blend_wmae = weighted_mae(y.values, blend_oof, w.values)\n",
    "print(\"Weighted Blending CV Weighted MAE:\", blend_wmae)\n",
    "\n",
    "# 6) 최종 예측 & 제출\n",
    "blend_test_pred = test_preds.dot(blend_weights)\n",
    "blend_test_pred = np.clip(blend_test_pred, 0.1, 0.9)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ID': test['ID'],\n",
    "    '성공확률': blend_test_pred\n",
    "})\n",
    "submission.to_csv('submission_2.csv', index=False)\n",
    "print(\"submission_2.csv 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb2787-d7f6-4c1e-b716-6e7f52c31ea1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
